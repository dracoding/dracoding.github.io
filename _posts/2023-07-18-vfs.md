---
layout: post
title: 【vfs】一、虚拟文件系统解析
date: 2023-07-18
tags:  vfs
---

## open系统调用

<div align="center">
<img src="/images/out/storage/open_syscall.png">  
</div> 


```
SYSCALL_DEFINE3(open, const char __user *, filename, int, flags, umode_t, mode)
{
        if (force_o_largefile())
                flags |= O_LARGEFILE;
        return do_sys_open(AT_FDCWD, filename, flags, mode);
}

long do_sys_open(int dfd, const char __user *filename, int flags, umode_t mode)
{
        struct open_how how = build_open_how(flags, mode);
        return do_sys_openat2(dfd, filename, &how);
}

static long do_sys_openat2(int dfd, const char __user *filename,
                           struct open_how *how)
{
        struct open_flags op;
        int fd = build_open_flags(how, &op);
        struct filename *tmp;

        if (fd)
                return fd;

        tmp = getname(filename);
        if (IS_ERR(tmp))
                return PTR_ERR(tmp);

        fd = get_unused_fd_flags(how->flags);
        if (fd >= 0) {
                struct file *f = do_filp_open(dfd, tmp, &op);
                if (IS_ERR(f)) {
                        put_unused_fd(fd);
                        fd = PTR_ERR(f);
                } else {
                        fsnotify_open(f);
                        fd_install(fd, f);
                }
        }
        putname(tmp);
        return fd;
}
```

do_filp_open -> path_openat

```
static struct file *path_openat(struct nameidata *nd,
                        const struct open_flags *op, unsigned flags)
{
        struct file *file;
        int error;

        file = alloc_empty_file(op->open_flag, current_cred());
        if (IS_ERR(file))
                return file;

        if (unlikely(file->f_flags & __O_TMPFILE)) {
                error = do_tmpfile(nd, flags, op, file);
        } else if (unlikely(file->f_flags & O_PATH)) {
                error = do_o_path(nd, flags, file);
        } else {
                const char *s = path_init(nd, flags);
                while (!(error = link_path_walk(s, nd)) &&
                       (s = open_last_lookups(nd, file, op)) != NULL)   // 查找文件对应的dentry,
                        ;
                if (!error)
                        error = do_open(nd, file, op);   // file和对应的path关联
                terminate_walk(nd);
        }
        if (likely(!error)) {
                if (likely(file->f_mode & FMODE_OPENED))
                        return file;
                WARN_ON(1);
                error = -EINVAL;
        }
        fput(file);
        if (error == -EOPENSTALE) {
                if (flags & LOOKUP_RCU)
                        error = -ECHILD;
                else 
                        error = -ESTALE;
        }
        return ERR_PTR(error);
}
```

## read系统调用

<div align="center">
<img src="/images/out/storage/read_syscall.png">  
</div> 

```
ssize_t ksys_read(unsigned int fd, char __user *buf, size_t count)
{
        struct fd f = fdget_pos(fd);
        ssize_t ret = -EBADF;

        if (f.file) {
                loff_t pos, *ppos = file_ppos(f.file);   // 文件的偏移
                if (ppos) {
                        pos = *ppos;
                        ppos = &pos;
                }
                ret = vfs_read(f.file, buf, count, ppos);
                if (ret >= 0 && ppos)
                        f.file->f_pos = pos;
                fdput_pos(f);
        }
        return ret;
}

SYSCALL_DEFINE3(read, unsigned int, fd, char __user *, buf, size_t, count)
{
        return ksys_read(fd, buf, count);
}
```

vfs_read

```
ssize_t vfs_read(struct file *file, char __user *buf, size_t count, loff_t *pos)
{
        ssize_t ret;

        if (!(file->f_mode & FMODE_READ))
                return -EBADF;
        if (!(file->f_mode & FMODE_CAN_READ))
                return -EINVAL;
        if (unlikely(!access_ok(buf, count)))
                return -EFAULT;

        ret = rw_verify_area(READ, file, pos, count);
        if (ret)
                return ret;
        if (count > MAX_RW_COUNT)
                count =  MAX_RW_COUNT;

        if (file->f_op->read)
                ret = file->f_op->read(file, buf, count, pos);  // xfs文件系统无此函数
        else if (file->f_op->read_iter)
                ret = new_sync_read(file, buf, count, pos);
        else
                ret = -EINVAL;
        if (ret > 0) {
                fsnotify_access(file);
                add_rchar(current, ret);
        }
        inc_syscr(current);
        return ret;
}
```

new_sync_read

```
static ssize_t new_sync_write(struct file *filp, const char __user *buf, size_t len, loff_t *ppos)
{
        struct iovec iov = { .iov_base = (void __user *)buf, .iov_len = len };
        struct kiocb kiocb;       // IO控制块
        struct iov_iter iter;   // 用户态和内核态传递数据
        ssize_t ret;    

        init_sync_kiocb(&kiocb, filp);
        kiocb.ki_pos = (ppos ? *ppos : 0);
        iov_iter_init(&iter, WRITE, &iov, 1, len);

        ret = call_write_iter(filp, &kiocb, &iter);
        BUG_ON(ret == -EIOCBQUEUED);
        if (ret > 0 && ppos)
                *ppos = kiocb.ki_pos;
        return ret;     
}

static inline ssize_t call_read_iter(struct file *file, struct kiocb *kio,
                                     struct iov_iter *iter)
{
        return file->f_op->read_iter(kio, iter);
}
```

xfs_file_read_iter

```
STATIC ssize_t
xfs_file_read_iter(
        struct kiocb            *iocb,
        struct iov_iter         *to)
{
        struct inode            *inode = file_inode(iocb->ki_filp);
        struct xfs_mount        *mp = XFS_I(inode)->i_mount;
        ssize_t                 ret = 0;

        XFS_STATS_INC(mp, xs_read_calls);

        if (XFS_FORCED_SHUTDOWN(mp))
                return -EIO;

        if (IS_DAX(inode))
                ret = xfs_file_dax_read(iocb, to);
        else if (iocb->ki_flags & IOCB_DIRECT)           // direct io
                ret = xfs_file_dio_aio_read(iocb, to);
        else
                ret = xfs_file_buffered_aio_read(iocb, to);

        if (ret > 0)
                XFS_STATS_ADD(mp, xs_read_bytes, ret);
        return ret;
}
```

xfs_file_buffered_aio_read -> generic_file_read_iter

```
ssize_t
generic_file_read_iter(struct kiocb *iocb, struct iov_iter *iter)
{
        size_t count = iov_iter_count(iter);
        ssize_t retval = 0;

        if (!count)
                goto out; /* skip atime */

        if (iocb->ki_flags & IOCB_DIRECT) {
                struct file *file = iocb->ki_filp;
                struct address_space *mapping = file->f_mapping;
                struct inode *inode = mapping->host;
                loff_t size;
                
                size = i_size_read(inode);
                if (iocb->ki_flags & IOCB_NOWAIT) {                           
                        if (filemap_range_has_page(mapping, iocb->ki_pos,
                                                   iocb->ki_pos + count - 1))
                                return -EAGAIN;
                } else {
                        retval = filemap_write_and_wait_range(mapping,
                                                iocb->ki_pos,
                                                iocb->ki_pos + count - 1);
                        if (retval < 0)
                                goto out;
                }

                file_accessed(file);

                retval = mapping->a_ops->direct_IO(iocb, iter);
                if (retval >= 0) {
                        iocb->ki_pos += retval;
                        count -= retval;
                }
                iov_iter_revert(iter, count - iov_iter_count(iter));


                if (retval < 0 || !count || iocb->ki_pos >= size ||
                    IS_DAX(inode))
                        goto out;
        }

        retval = generic_file_buffered_read(iocb, iter, retval);
out:
        return retval;
}
```

generic_file_buffered_read -> generic_file_buffered_read_get_pages

```
static int generic_file_buffered_read_get_pages(struct kiocb *iocb,
                                                struct iov_iter *iter,
                                                struct page **pages,
                                                unsigned int nr)
{
        struct file *filp = iocb->ki_filp;
        struct address_space *mapping = filp->f_mapping;
        struct file_ra_state *ra = &filp->f_ra;
        pgoff_t index = iocb->ki_pos >> PAGE_SHIFT;
        pgoff_t last_index = (iocb->ki_pos + iter->count + PAGE_SIZE-1) >> PAGE_SHIFT;
        int i, j, nr_got, err = 0;

        nr = min_t(unsigned long, last_index - index, nr);
find_page:
        if (fatal_signal_pending(current))
                return -EINTR;

        nr_got = find_get_pages_contig(mapping, index, nr, pages);
        if (nr_got)
                goto got_pages;

        if (iocb->ki_flags & IOCB_NOIO)
                return -EAGAIN;

        page_cache_sync_readahead(mapping, ra, filp, index, last_index - index);

        nr_got = find_get_pages_contig(mapping, index, nr, pages);
        if (nr_got)
                goto got_pages;

        pages[0] = generic_file_buffered_read_no_cached_page(iocb, iter);
        err = PTR_ERR_OR_ZERO(pages[0]);
        if (!IS_ERR_OR_NULL(pages[0]))
                nr_got = 1;
got_pages:
        for (i = 0; i < nr_got; i++) {
                struct page *page = pages[i];
                pgoff_t pg_index = index + i;
                loff_t pg_pos = max(iocb->ki_pos,
                                    (loff_t) pg_index << PAGE_SHIFT);
                loff_t pg_count = iocb->ki_pos + iter->count - pg_pos;

                if (PageReadahead(page)) {
                        if (iocb->ki_flags & IOCB_NOIO) {
                                for (j = i; j < nr_got; j++)
                                        put_page(pages[j]);
                                nr_got = i;
                                err = -EAGAIN;
                                break;
                        }
                        page_cache_async_readahead(mapping, ra, filp, page,
                                        pg_index, last_index - pg_index);
                }

                if (!PageUptodate(page)) {
                        if ((iocb->ki_flags & IOCB_NOWAIT) ||
                            ((iocb->ki_flags & IOCB_WAITQ) && i)) {
                                for (j = i; j < nr_got; j++)
                                        put_page(pages[j]);
                                nr_got = i;
                                err = -EAGAIN;
                                break;
                        }

                        page = generic_file_buffered_read_pagenotuptodate(iocb,
                                        filp, iter, page, pg_pos, pg_count);
                        if (IS_ERR_OR_NULL(page)) {
                                for (j = i + 1; j < nr_got; j++)
                                        put_page(pages[j]);
                                nr_got = i;
                                err = PTR_ERR_OR_ZERO(page);
                                break;
                        }
                }
        }

        if (likely(nr_got))
                return nr_got;
        if (err)
                return err;
        /*
         * No pages and no error means we raced and should retry:
         */
        goto find_page;
}
```

## write系统调用

<div align="center">
<img src="/images/out/storage/write_syscall.png">  
</div> 

```
ssize_t ksys_write(unsigned int fd, const char __user *buf, size_t count)
{
        struct fd f = fdget_pos(fd);
        ssize_t ret = -EBADF;

        if (f.file) {
                loff_t pos, *ppos = file_ppos(f.file);
                if (ppos) {
                        pos = *ppos;
                        ppos = &pos;
                }
                ret = vfs_write(f.file, buf, count, ppos);
                if (ret >= 0 && ppos)
                        f.file->f_pos = pos;
                fdput_pos(f);
        }

        return ret;
}

SYSCALL_DEFINE3(write, unsigned int, fd, const char __user *, buf,
                size_t, count)
{
        return ksys_write(fd, buf, count);
}

```
vfs_write

```
ssize_t vfs_write(struct file *file, const char __user *buf, size_t count, loff_t *pos)
{
        ssize_t ret;

        if (!(file->f_mode & FMODE_WRITE))
                return -EBADF;
        if (!(file->f_mode & FMODE_CAN_WRITE))
                return -EINVAL;
        if (unlikely(!access_ok(buf, count)))
                return -EFAULT;

        ret = rw_verify_area(WRITE, file, pos, count);
        if (ret)
                return ret;
        if (count > MAX_RW_COUNT)
                count =  MAX_RW_COUNT;
        file_start_write(file);
        if (file->f_op->write)
                ret = file->f_op->write(file, buf, count, pos);
        else if (file->f_op->write_iter)
                ret = new_sync_write(file, buf, count, pos);
        else
                ret = -EINVAL;
        if (ret > 0) {
                fsnotify_modify(file);
                add_wchar(current, ret);
        }
        inc_syscw(current);
        file_end_write(file);
        return ret;
}

```

new_sync_write -> call_write_iter

```
static ssize_t new_sync_write(struct file *filp, const char __user *buf, size_t len, loff_t *ppos)
{
        struct iovec iov = { .iov_base = (void __user *)buf, .iov_len = len };
        struct kiocb kiocb;
        struct iov_iter iter;
        ssize_t ret;

        init_sync_kiocb(&kiocb, filp);
        kiocb.ki_pos = (ppos ? *ppos : 0);
        iov_iter_init(&iter, WRITE, &iov, 1, len);

        ret = call_write_iter(filp, &kiocb, &iter);
        BUG_ON(ret == -EIOCBQUEUED);
        if (ret > 0 && ppos)
                *ppos = kiocb.ki_pos;
        return ret;
}

static inline ssize_t call_write_iter(struct file *file, struct kiocb *kio,
                                      struct iov_iter *iter)
{
        return file->f_op->write_iter(kio, iter);
}
```

xfs_file_write_iter

```
STATIC ssize_t
xfs_file_write_iter(
        struct kiocb            *iocb,
        struct iov_iter         *from)
{
        struct file             *file = iocb->ki_filp;
        struct address_space    *mapping = file->f_mapping;
        struct inode            *inode = mapping->host;
        struct xfs_inode        *ip = XFS_I(inode);
        ssize_t                 ret;
        size_t                  ocount = iov_iter_count(from);

        XFS_STATS_INC(ip->i_mount, xs_write_calls);

        if (ocount == 0)
                return 0;

        if (XFS_FORCED_SHUTDOWN(ip->i_mount))
                return -EIO;

        if (IS_DAX(inode))
                return xfs_file_dax_write(iocb, from);

        if (iocb->ki_flags & IOCB_DIRECT) {
                /*
                 * Allow a directio write to fall back to a buffered
                 * write *only* in the case that we're doing a reflink
                 * CoW.  In all other directio scenarios we do not
                 * allow an operation to fall back to buffered mode.
                 */
                ret = xfs_file_dio_aio_write(iocb, from);
                if (ret != -ENOTBLK)
                        return ret;
        }

        return xfs_file_buffered_aio_write(iocb, from);
}

```

xfs_file_dio_aio_write -> xfs_file_buffered_aio_write

```
STATIC ssize_t
xfs_file_buffered_aio_write(
        struct kiocb            *iocb,
        struct iov_iter         *from)
{
        struct file             *file = iocb->ki_filp;
        struct address_space    *mapping = file->f_mapping;
        struct inode            *inode = mapping->host;
        struct xfs_inode        *ip = XFS_I(inode);
        ssize_t                 ret;
        bool                    cleared_space = false;
        int                     iolock;

        if (iocb->ki_flags & IOCB_NOWAIT)
                return -EOPNOTSUPP;

write_retry:
        iolock = XFS_IOLOCK_EXCL;
        xfs_ilock(ip, iolock);

        ret = xfs_file_aio_write_checks(iocb, from, &iolock);
        if (ret)
                goto out;

        /* We can write back this queue in page reclaim */
        current->backing_dev_info = inode_to_bdi(inode);

        trace_xfs_file_buffered_write(ip, iov_iter_count(from), iocb->ki_pos);
        ret = iomap_file_buffered_write(iocb, from,
                        &xfs_buffered_write_iomap_ops);
        if (likely(ret >= 0))
                iocb->ki_pos += ret;

        if (ret == -EDQUOT && !cleared_space) {
                xfs_iunlock(ip, iolock);
                xfs_blockgc_free_quota(ip, XFS_ICWALK_FLAG_SYNC);
                cleared_space = true;
                goto write_retry;
        } else if (ret == -ENOSPC && !cleared_space) {
                struct xfs_icwalk       icw = {0};

                cleared_space = true;
                xfs_flush_inodes(ip->i_mount);

                xfs_iunlock(ip, iolock);
                icw.icw_flags = XFS_ICWALK_FLAG_SYNC;
                xfs_blockgc_free_space(ip->i_mount, &icw);
                goto write_retry;
        }

        current->backing_dev_info = NULL;
out:
        if (iolock)
                xfs_iunlock(ip, iolock);

        if (ret > 0) {
                XFS_STATS_ADD(ip->i_mount, xs_write_bytes, ret);
                /* Handle various SYNC-type writes */
                ret = generic_write_sync(iocb, ret);
        }
        return ret;
}
```
iomap_file_buffered_write

```
ssize_t
iomap_file_buffered_write(struct kiocb *iocb, struct iov_iter *iter,
                const struct iomap_ops *ops)
{
        struct inode *inode = iocb->ki_filp->f_mapping->host;
        loff_t pos = iocb->ki_pos, ret = 0, written = 0;

        while (iov_iter_count(iter)) {
                ret = iomap_apply(inode, pos, iov_iter_count(iter),
                                IOMAP_WRITE, ops, iter, iomap_write_actor);
                if (ret <= 0)
                        break;
                pos += ret;
                written += ret;
        }

        return written ? written : ret;
}
```

写入参盘的函数为iomap_write_actor， 

```
static loff_t
iomap_write_actor(struct inode *inode, loff_t pos, loff_t length, void *data,
                struct iomap *iomap, struct iomap *srcmap)
{
        struct iov_iter *i = data;
        long status = 0;
        ssize_t written = 0;

        do {
                struct page *page;
                unsigned long offset;   /* Offset into pagecache page */
                unsigned long bytes;    /* Bytes to write to page */
                size_t copied;          /* Bytes copied from user */

                offset = offset_in_page(pos);
                bytes = min_t(unsigned long, PAGE_SIZE - offset,
                                                iov_iter_count(i));
again:
                if (bytes > length)
                        bytes = length;

                /*
                 * Bring in the user page that we will copy from _first_.
                 * Otherwise there's a nasty deadlock on copying from the
                 * same page as we're writing to, without it being marked
                 * up-to-date.
                 */
                if (unlikely(iov_iter_fault_in_readable(i, bytes))) {
                        status = -EFAULT;
                        break;
                }

                status = iomap_write_begin(inode, pos, bytes, 0, &page, iomap,
                                srcmap);
                if (unlikely(status))
                        break;

                if (mapping_writably_mapped(inode->i_mapping))
                        flush_dcache_page(page);

                copied = iov_iter_copy_from_user_atomic(page, i, offset, bytes);

                status = iomap_write_end(inode, pos, bytes, copied, page, iomap,
                                srcmap);

                cond_resched();
                if (unlikely(status == 0)) {
                        /*
                         * A short copy made iomap_write_end() reject the
                         * thing entirely.  Might be memory poisoning
                         * halfway through, might be a race with munmap,
                         * might be severe memory pressure.
                         */
                        if (copied)
                                bytes = copied;
                        goto again;
                }
                copied = status;
                iov_iter_advance(i, copied);
                pos += copied;
                written += copied;
                length -= copied;

                balance_dirty_pages_ratelimited(inode->i_mapping);
        } while (iov_iter_count(i) && length);

        return written ? written : status;
}       
```


<br>
转载请注明： [【vfs】一、虚拟文件系统解析](https://dracoding.github.io/2023/06/vfs/) 
